{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5ae18-d98d-4c33-95fd-0dc82ad3ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models.IModelUplift import IModelUplift\n",
    "from src.datasets import TorchDataset\n",
    "from src.metric import get_auuc_v2\n",
    "\n",
    "class INNUpliftModeling(IModelUplift):\n",
    "    \"\"\"\n",
    "    Родительский класс для реализации нейросетевых моделей аплифт-моделирования.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_json=None, from_load=False, path=None):\n",
    "        \"\"\"\n",
    "        Инициализация объекта модели.\n",
    "        \n",
    "        Args:\n",
    "            config_json: строка с JSON-конфигурацией модели\n",
    "            from_load: флаг, указывающий, что модель загружается из файла\n",
    "            path: путь для загрузки модели\n",
    "        \"\"\"\n",
    "        super().__init__(config_json, from_load, path)\n",
    "\n",
    "        if from_load == False:\n",
    "            if config_json is None:\n",
    "                raise ValueError(f\"No config while contstructing model.\")\n",
    "\n",
    "            if isinstance(config_json, str):\n",
    "                self.config = json.loads(config_json)\n",
    "            else:\n",
    "                self.config = config_json\n",
    "            self.model = None\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() and self.config.get('use_gpu', True) else 'cpu')\n",
    "            self._initialize_model()\n",
    "            self._setup_optimizer_and_scheduler()\n",
    "            self.history = {}\n",
    "        else:\n",
    "            if path is None:\n",
    "                raise ValueError(f\"No config or model paths while contstructing model.\")\n",
    "            self.load(path)\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        pass\n",
    "    \n",
    "    def _setup_optimizer_and_scheduler(self):\n",
    "        \"\"\"\n",
    "        Инициализация оптимизатора и планировщика лр.\n",
    "        \"\"\"\n",
    "        optimizer_config = self.config.get('optimizer', {})\n",
    "        optimizer_name = optimizer_config.get('name', 'Adam')\n",
    "        lr = optimizer_config.get('lr', 0.001)\n",
    "        weight_decay = optimizer_config.get('weight_decay', 0.0)\n",
    "        \n",
    "        if optimizer_name == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                self.model.parameters(), \n",
    "                lr=lr, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        elif optimizer_name == 'SGD':\n",
    "            momentum = optimizer_config.get('momentum', 0.9)\n",
    "            self.optimizer = torch.optim.SGD(\n",
    "                self.model.parameters(), \n",
    "                lr=lr, \n",
    "                momentum=momentum, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        elif optimizer_name == 'AdamW':\n",
    "            self.optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(), \n",
    "                lr=lr, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        else:\n",
    "                self.optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(), \n",
    "                lr=lr, \n",
    "                weight_decay=weight_decay\n",
    "            )\n",
    "        \n",
    "        scheduler_config = self.config.get('scheduler', {})\n",
    "        scheduler_name = scheduler_config.get('name')\n",
    "        \n",
    "        if scheduler_name == 'ReduceLROnPlateau':\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer,\n",
    "                mode=scheduler_config.get('mode', 'min'),\n",
    "                factor=scheduler_config.get('factor', 0.1),\n",
    "                patience=scheduler_config.get('patience', 10),\n",
    "                verbose=scheduler_config.get('verbose', True)\n",
    "            )\n",
    "        elif scheduler_name == 'CosineAnnealingLR':\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer,\n",
    "                T_max=scheduler_config.get('T_max', 100),\n",
    "                eta_min=scheduler_config.get('eta_min', 0)\n",
    "            )\n",
    "        elif scheduler_name is None:\n",
    "            self.scheduler = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler: {scheduler_name}\")\n",
    "    \n",
    "    def _prepare_data_loader(self, X: TorchDataset, batch_size=None, shuffle=False):\n",
    "        \"\"\"\n",
    "        Подготовка DataLoader\n",
    "        \"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "            \n",
    "        return DataLoader(\n",
    "            X, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=shuffle,\n",
    "            drop_last=True,\n",
    "            num_workers=self.config.get('num_workers', 0)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def _compute_loss(self, outputs, outcome, treatment):\n",
    "        \"\"\"\n",
    "        Вычисление лосса\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: TorchDataset):\n",
    "        \"\"\"\n",
    "        Обучение модели с валидацией.            \n",
    "        История обучения (словарь с метриками по эпохам)\n",
    "        \"\"\"\n",
    "        train_size = int(0.8 * len(X_train))\n",
    "        val_size = len(X_train) - train_size\n",
    "        X_train, X_val = torch.utils.data.random_split(X_train, [train_size, val_size])\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        epochs = self.config.get('epochs', 10)\n",
    "        batch_size = self.config.get('batch_size', 32)\n",
    "        early_stopping_patience = self.config.get('early_stopping_patience', 2)\n",
    "        accumulation_steps = self.config.get('gradient_accumulation_steps', 1)\n",
    "        effective_batch_size = batch_size * accumulation_steps\n",
    "        \n",
    "        train_loader = self._prepare_data_loader(X_train, batch_size, shuffle=True)\n",
    "        val_loader = self._prepare_data_loader(X_val, batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_val_auuc = float('-inf')\n",
    "        early_stopping_criterion = self.config.get('early_stopping_criterion', 'loss')  # 'loss' или 'auuc'\n",
    "        patience_counter = 0\n",
    "        \n",
    "        history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_auuc': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            self.model.train()\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                self.model.train()\n",
    "                features, treatment, outcome = batch     \n",
    "                \n",
    "                outputs = self.model(features)\n",
    "                \n",
    "                loss = self._compute_loss(outputs, outcome, treatment) / accumulation_steps\n",
    "                loss.backward()\n",
    "                \n",
    "                epoch_loss += loss.item() * accumulation_steps\n",
    "                num_batches += 1\n",
    "                \n",
    "                if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    if (batch_idx + 1) % max(1, len(train_loader) // 10) == 0:\n",
    "                        progress = (batch_idx + 1) / len(train_loader) * 100\n",
    "                        current_loss = epoch_loss / num_batches\n",
    "                        print(f\"Epoch {epoch+1}/{epochs} - {progress:.1f}% - Loss: {current_loss:.4f}\")\n",
    "             \n",
    "            avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "            # ---- validation ----\n",
    "            print(f\"Validation after epoch\")\n",
    "            val_loss, val_auuc = self._evaluate(val_loader)\n",
    "            \n",
    "            if self.scheduler is not None:\n",
    "                if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    self.scheduler.step(val_loss)\n",
    "                else:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            \n",
    "            history['epoch'].append(epoch + 1)\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_auuc'].append(val_auuc)\n",
    "            history['learning_rate'].append(self.optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val AUUC: {val_auuc:.4f}, \"\n",
    "                  f\"LR: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            \n",
    "            if early_stopping_criterion == 'loss' and val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                \n",
    "                best_model_state = {name: param.clone() for name, param in self.model.state_dict().items()}\n",
    "            elif early_stopping_criterion == 'auuc' and val_auuc > best_val_auuc:\n",
    "                best_val_auuc = val_auuc\n",
    "                patience_counter = 0\n",
    "                \n",
    "                best_model_state = {name: param.clone() for name, param in self.model.state_dict().items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                    \n",
    "                    self.model.load_state_dict(best_model_state)\n",
    "                    break\n",
    "        \n",
    "        self.history = history\n",
    "\n",
    "    def _evaluate(self, data_loader):\n",
    "        \"\"\"\n",
    "        loss и AUUC на валидационном или тестовом наборе.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        all_uplift_scores = []\n",
    "        all_treatments = []\n",
    "        all_outcomes = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                features, treatment, outcome = batch\n",
    "            \n",
    "                outputs = self.model(features)                \n",
    "                loss = self._compute_loss(outputs, outcome, treatment)\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                uplift_scores = outputs[\"uplift\"]\n",
    "                all_uplift_scores.append(uplift_scores.cpu())\n",
    "                all_treatments.append(treatment.cpu())\n",
    "                all_outcomes.append(outcome.cpu())\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        auuc = float('nan')\n",
    "    \n",
    "        uplift_scores = torch.cat(all_uplift_scores, dim=0).numpy().flatten()\n",
    "        treatments = torch.cat(all_treatments, dim=0).numpy().flatten()\n",
    "        outcomes = torch.cat(all_outcomes, dim=0).numpy().flatten()                \n",
    "        auuc = get_auuc_v2(uplift_scores, treatments, outcomes)\n",
    "        \n",
    "        return avg_loss, auuc\n",
    "        \n",
    "    def predict(self, X: TorchDataset):\n",
    "        \"\"\"\n",
    "        Предсказание вероятностей и аплифт-скоров.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        batch_size = self.config.get('inference_batch_size', 32)\n",
    "        data_loader = self._prepare_data_loader(X, batch_size, shuffle=False)\n",
    "        \n",
    "        uplift_list, treatment_list, outcome_list = [], [], []\n",
    "        p_estr_list, p_escr_list, p_prpsy_list = [], [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                features, treatment, outcome = batch\n",
    "                \n",
    "                outputs = self.model(features)\n",
    "                \n",
    "                uplift_list.append(outputs['uplift'].cpu())\n",
    "                treatment_list.append(treatment.cpu())\n",
    "                outcome_list.append(outcome.cpu())\n",
    "\n",
    "                p_estr_list.append(outputs[\"p_estr\"].cpu())\n",
    "                p_escr_list.append(outputs[\"p_escr\"].cpu())\n",
    "                p_prpsy_list.append(outputs[\"p_prpsy\"].cpu())\n",
    "                \n",
    "        uplift = torch.cat(uplift_list, dim=0).numpy()\n",
    "        treatment = torch.cat(treatment_list, dim=0).numpy()\n",
    "        outcome = torch.cat(outcome_list, dim=0).numpy()\n",
    "\n",
    "        p_estr = torch.cat(p_estr_list, dim=0).numpy()\n",
    "        p_escr = torch.cat(p_escr_list, dim=0).numpy()\n",
    "        p_prpsy = torch.cat(p_prpsy_list, dim=0).numpy()\n",
    "\n",
    "        df = pd.DataFrame({'score': uplift[:, 0], 'treatment': treatment, 'target':outcome})\n",
    "        return {\n",
    "            'uplift': uplift,\n",
    "            'df': df,\n",
    "            'p_estr': p_estr,\n",
    "            'p_escr': p_escr,\n",
    "            'p_prpsy': p_prpsy\n",
    "        }\n",
    "    \n",
    "    def predict_light(self, X: DataLoader):\n",
    "        pass\n",
    "    #     \"\"\"\n",
    "    #     Легкая версия предсказания (без возврата значений).\n",
    "    #     \"\"\"\n",
    "    #     self.model.eval()\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         for batch in X:\n",
    "    #             features, treatment, _ = batch\n",
    "    #             _ = self.model(features)\n",
    "    \n",
    "    def save(self, path_current_setup):\n",
    "        \"\"\"\n",
    "        Сохранение модели в файл.\n",
    "        \"\"\"\n",
    "        path = os.path.join(path_current_setup, \"model.pkl\")\n",
    "        \n",
    "        # Подготовка данных для сохранения\n",
    "        save_data = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'history': self.history\n",
    "        }\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            save_data['scheduler_state_dict'] = self.scheduler.state_dict()\n",
    "        \n",
    "        torch.save(save_data, path)\n",
    "    \n",
    "    def load(self, path_current_setup):\n",
    "        \"\"\"\n",
    "        Загрузка модели из файла.\n",
    "        \"\"\"\n",
    "        path = os.path.join(path_current_setup, \"model.pkl\")\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "            \n",
    "        checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        self.config = checkpoint['config']\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and \n",
    "                                  self.config.get('use_gpu', True) else 'cpu')\n",
    "        \n",
    "        self._initialize_model()\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        self._setup_optimizer_and_scheduler()\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        self.history = checkpoint['history']\n",
    "        \n",
    "        if 'scheduler_state_dict' in checkpoint and self.scheduler is not None:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    def measure_inference_time(self, data, batch_size, max_size=None):\n",
    "        \"\"\"\n",
    "        Измерение среднего времени инференса модели на данных.\n",
    "        \"\"\"\n",
    "        max_size = 5000\n",
    "        batch_size=32\n",
    "        indices = torch.randperm(len(data))[:max_size]\n",
    "        subset_data = torch.utils.data.Subset(data, indices)\n",
    "        data_loader = self._prepare_data_loader(subset_data, batch_size, shuffle=False)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Измерение времени\n",
    "        inference_times = []\n",
    "    \n",
    "        cur_size = 0\n",
    "        for batch in data_loader:\n",
    "            features, _, _ = batch\n",
    "            start_time = time.time()\n",
    "            _ = self.model(features)\n",
    "            end_time = time.time() \n",
    "            \n",
    "            inference_times.append((end_time - start_time) * 1000 / batch_size)\n",
    "    \n",
    "            cur_size += batch_size\n",
    "            if cur_size >= max_size:\n",
    "                break\n",
    "    \n",
    "        mean_inference_time = np.mean(inference_times)\n",
    "        return mean_inference_time\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_config(count, params):\n",
    "        \"\"\"\n",
    "        Генерация набора конфигураций для различных моделей.\n",
    "        count: количество конфигураций для генерации\n",
    "        **params: дополнительные параметры и диапазоны для конфигураций\n",
    "        \"\"\"\n",
    "        configs = []\n",
    "        \n",
    "        base_config = {\n",
    "            'batch_size': 64,\n",
    "            'epochs': 10,\n",
    "            'early_stopping_patience': 2,\n",
    "            'optimizer': {\n",
    "                'name': 'Adam',\n",
    "                'lr': 0.005,\n",
    "                'weight_decay': 0.001\n",
    "            },\n",
    "            'scheduler': {\n",
    "                'name': 'ReduceLROnPlateau',\n",
    "                'patience': 1,\n",
    "                'factor': 0.5\n",
    "            },\n",
    "            'use_gpu': True,\n",
    "            'num_workers': 0,\n",
    "            'inference_batch_size': 32\n",
    "        }\n",
    "        \n",
    "        for key, value in params.items():\n",
    "            if isinstance(value, list):\n",
    "                base_config[key] = value[0]\n",
    "            else:\n",
    "                base_config[key] = value\n",
    "        \n",
    "        # Генерация вариаций конфигураций\n",
    "        for i in range(count):\n",
    "            config = base_config.copy()\n",
    "            \n",
    "            for key, value in params.items():\n",
    "                if isinstance(value, list):\n",
    "                    config[key] = np.random.choice(value)\n",
    "                elif isinstance(value, tuple) and len(value) == 2:\n",
    "                    min_val, max_val = value\n",
    "                    if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                        config[key] = np.random.randint(min_val, max_val + 1)\n",
    "                    else:\n",
    "                        config[key] = np.random.uniform(min_val, max_val)\n",
    "            \n",
    "            configs.append(config)\n",
    "        \n",
    "        return configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505abea-c70a-4f59-a51e-21b559c74409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "from torch.utils.data import DataLoader, TensorDataset as TorchDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.models.NNUpliftModeling.INNUpliftModeling import INNUpliftModeling\n",
    "from src.models.NNUpliftModeling.DESCN import *\n",
    "\n",
    "\n",
    "class DESCNUpliftModel(INNUpliftModeling):\n",
    "    \"\"\"\n",
    "    DESCN для аплифт-моделирования.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        input_dim = self.config.get('input_dim')\n",
    "        share_dim = self.config.get('share_dim', 128)\n",
    "        base_dim = self.config.get('base_dim', 64)\n",
    "        do_rate = self.config.get('do_rate', 0.2)\n",
    "        batch_norm = self.config.get('batch_norm', False)\n",
    "        normalization = self.config.get('normalization', 'none')\n",
    "        \n",
    "        if input_dim is None:\n",
    "            raise ValueError(\"input_dim must be specified in the config\")\n",
    "\n",
    "        self.model = DESCN(\n",
    "            input_dim=input_dim,\n",
    "            share_dim=share_dim,\n",
    "            base_dim=base_dim,\n",
    "            do_rate=do_rate,\n",
    "            device=self.device,\n",
    "            batch_norm=batch_norm,\n",
    "            normalization=normalization\n",
    "        )\n",
    "    \n",
    "    def _compute_loss(self, outputs, outcome, treatment):\n",
    "        \"\"\"\n",
    "        Вычисление функции потерь для DESCN.\n",
    "        \"\"\"\n",
    "        # Распаковка необходимых выходов модели\n",
    "        p_prpsy_logit = outputs['p_prpsy_logit']\n",
    "        p_estr = outputs['p_estr']\n",
    "        p_escr = outputs['p_escr']\n",
    "        p_tau_logit = outputs['tau_logit']\n",
    "        p_mu1_logit = outputs['mu1_logit']\n",
    "        p_mu0_logit = outputs['mu0_logit']\n",
    "        shared_h = outputs['shared_h']\n",
    "        \n",
    "        # Веса для разных компонентов потери из конфигурации\n",
    "        prpsy_w = self.config.get('prpsy_w', 1.0)\n",
    "        escvr1_w = self.config.get('escvr1_w', 1.0)\n",
    "        escvr0_w = self.config.get('escvr0_w', 1.0)\n",
    "        mu1hat_w = self.config.get('mu1hat_w', 1.0)\n",
    "        mu0hat_w = self.config.get('mu0hat_w', 1.0)\n",
    "        \n",
    "        # Преобразование целевой переменной и индикатора воздействия\n",
    "        y_labels = outcome.unsqueeze(1).float()\n",
    "        t_labels = treatment.unsqueeze(1).float()\n",
    "        \n",
    "        # Маски для групп воздействия и контроля\n",
    "        treatment_mask = t_labels.bool()\n",
    "        control_mask = ~treatment_mask\n",
    "        \n",
    "        loss_fn = nn.BCELoss()\n",
    "        loss_with_logit_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        prpsy_loss = prpsy_w * loss_with_logit_fn(p_prpsy_logit, t_labels)\n",
    "        \n",
    "        estr_loss = escvr1_w * loss_fn(p_estr, y_labels * t_labels)\n",
    "        escr_loss = escvr0_w * loss_fn(p_escr, y_labels * (1 - t_labels))\n",
    "\n",
    "        cross_tr_loss = mu1hat_w * loss_fn(\n",
    "            torch.sigmoid(p_mu0_logit + p_tau_logit)[treatment_mask],\n",
    "            y_labels[treatment_mask]\n",
    "        )\n",
    "\n",
    "        cross_tr_loss = 0.0 if torch.isnan(cross_tr_loss) else cross_tr_loss\n",
    "        \n",
    "        cross_cr_loss = mu0hat_w * loss_fn(\n",
    "            torch.sigmoid(p_mu1_logit - p_tau_logit)[control_mask],\n",
    "            y_labels[control_mask]\n",
    "        )\n",
    "\n",
    "        cross_cr_loss = 0.0 if torch.isnan(cross_cr_loss) else cross_cr_loss\n",
    "\n",
    "        # print(prpsy_loss, estr_loss, escr_loss, cross_cr_loss, cross_tr_loss)\n",
    "        total_loss = prpsy_loss + estr_loss + escr_loss + cross_tr_loss + cross_cr_loss\n",
    "        # print(total_loss)\n",
    "        if torch.isnan(total_loss):\n",
    "            print(prpsy_loss, estr_loss, escr_loss, cross_cr_loss, cross_tr_loss)\n",
    "            print(y_labels, y_labels.shape)\n",
    "            print(treatment_mask, treatment_mask.shape)\n",
    "            print(y_labels[treatment_mask])\n",
    "            print(p_mu0_logit + p_tau_logit)\n",
    "            print(torch.sigmoid(p_mu0_logit + p_tau_logit)[treatment_mask])\n",
    "            print(mu1hat_w)\n",
    "            \n",
    "            raise\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def _process_prediction_outputs(self, outputs):\n",
    "        \"\"\"\n",
    "        Обработка выходов модели для предсказания.\n",
    "        \n",
    "        Args:\n",
    "            outputs: выходы модели\n",
    "            \n",
    "        Returns:\n",
    "            Словарь с предсказанными значениями\n",
    "        \"\"\"\n",
    "        # Выделяем и преобразуем нужные для предсказания поля\n",
    "        return {\n",
    "            'y0': outputs['mu0_logit'],\n",
    "            'y1': outputs['mu1_logit'],\n",
    "            'uplift': outputs['uplift'],\n",
    "            'propensity': outputs['p_prpsy']\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_config(count, params):\n",
    "        \"\"\"\n",
    "        Генерация конфигураций для DESCN модели.\n",
    "        \n",
    "        Args:\n",
    "            count: количество конфигураций\n",
    "            **params: дополнительные параметры\n",
    "            \n",
    "        Returns:\n",
    "            Список конфигураций\n",
    "        \"\"\"\n",
    "        # Базовые параметры для DESCN\n",
    "        descn_params = {\n",
    "            'input_dim': 100,             # Должно быть задано в соответствии с данными\n",
    "            'share_dim': [256, 256], # Варианты размерности общих слоев\n",
    "            'base_dim': [256],   # Варианты размерности базовых слоев\n",
    "            'do_rate': [0.1, 0.2, 0.3],  # Варианты dropout\n",
    "            'batch_norm': [True, False], # Использование BatchNorm\n",
    "            'normalization': ['none', 'divide'], # Тип нормализации\n",
    "            'prpsy_w': 0.5,   # Вес для потери пропенсити\n",
    "            'escvr1_w': 0.5,  # Вес для потери ESTR\n",
    "            'escvr0_w': 1.0,  # Вес для потери ESCR\n",
    "            'mu1hat_w': 1.0,  # Вес для перекрестной потери TR\n",
    "            'mu0hat_w': 0.5,  # Вес для перекрестной потери CR\n",
    "            'gradient_accumulation_steps' : 2 # Количество шагов для аккумуляции градиентов\n",
    "        }\n",
    "        \n",
    "        # Объединение с переданными параметрами\n",
    "        for key, value in params.items():\n",
    "            descn_params[key] = value\n",
    "        \n",
    "        # Генерация конфигураций с использованием базового метода\n",
    "        return INNUpliftModeling.generate_config(count, descn_params)\n",
    "\n",
    "    def num_params(self):\n",
    "        return sum([p.numel() for p in self.model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4133f2f-febf-4be8-82dc-6a10c286febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        stdv = 1 / math.sqrt(m.weight.size(1))\n",
    "        torch.nn.init.normal_(m.weight, mean=0.0, std=stdv)\n",
    "        # torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def safe_sqrt(x):\n",
    "    ''' Numerically safe version of Pytoch sqrt '''\n",
    "    return torch.sqrt(torch.clip(x, 1e-9, 1e+9))\n",
    "\n",
    "class ShareNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, share_dim, base_dim, cfg, device):\n",
    "        super(ShareNetwork, self).__init__()\n",
    "        if cfg.get('BatchNorm1d', 'false') == 'true':\n",
    "            self.DNN = nn.Sequential(\n",
    "                nn.BatchNorm1d(input_dim),\n",
    "                nn.Linear(input_dim, share_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "                nn.Linear(share_dim, share_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "                nn.Linear(share_dim, base_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=cfg.get('do_rate', 0.2))\n",
    "            )\n",
    "        else:\n",
    "            self.DNN = nn.Sequential(\n",
    "                nn.Linear(input_dim, share_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "                nn.Linear(share_dim, share_dim),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "                nn.Linear(share_dim, base_dim),\n",
    "                nn.ELU(),\n",
    "            )\n",
    "\n",
    "        self.DNN.apply(init_weights)\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        h_rep = self.DNN(x)\n",
    "        if self.cfg.get('normalization', 'none') == \"divide\":\n",
    "            h_rep_norm = h_rep / safe_sqrt(torch.sum(torch.square(h_rep), dim=1, keepdim=True))\n",
    "        else:\n",
    "            h_rep_norm = 1.0 * h_rep\n",
    "        return h_rep_norm\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, base_dim, cfg):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.DNN = nn.Sequential(\n",
    "            nn.Linear(base_dim, base_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "            nn.Linear(base_dim, base_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=cfg.get('do_rate', 0.2)),\n",
    "            nn.Linear(base_dim, base_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=cfg.get('do_rate', 0.2))\n",
    "        )\n",
    "        self.DNN.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.DNN(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PrpsyNetwork(nn.Module):\n",
    "    \"\"\"propensity network\"\"\"\n",
    "    def __init__(self, base_dim, cfg):\n",
    "        super(PrpsyNetwork, self).__init__()\n",
    "        self.baseModel = BaseModel(base_dim, cfg)\n",
    "        self.logitLayer = nn.Linear(base_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.logitLayer.apply(init_weights)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.baseModel(inputs)\n",
    "        p = self.logitLayer(inputs)\n",
    "        return p\n",
    "\n",
    "\n",
    "class Mu0Network(nn.Module):\n",
    "    def __init__(self, base_dim, cfg):\n",
    "        super(Mu0Network, self).__init__()\n",
    "        self.baseModel = BaseModel(base_dim, cfg)\n",
    "        self.logitLayer = nn.Linear(base_dim, 1)\n",
    "        self.logitLayer.apply(init_weights)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.baseModel(inputs)\n",
    "        p = self.logitLayer(inputs)\n",
    "        return p\n",
    "\n",
    "\n",
    "class Mu1Network(nn.Module):\n",
    "    def __init__(self, base_dim, cfg):\n",
    "        super(Mu1Network, self).__init__()\n",
    "        self.baseModel = BaseModel(base_dim, cfg)\n",
    "        self.logitLayer = nn.Linear(base_dim, 1)\n",
    "        self.logitLayer.apply(init_weights)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.baseModel(inputs)\n",
    "        p = self.logitLayer(inputs)\n",
    "        return p\n",
    "\n",
    "\n",
    "class TauNetwork(nn.Module):\n",
    "    \"\"\"pseudo tau network\"\"\"\n",
    "    def __init__(self, base_dim, cfg):\n",
    "        super(TauNetwork, self).__init__()\n",
    "        self.baseModel = BaseModel(base_dim, cfg)\n",
    "        self.logitLayer = nn.Linear(base_dim, 1)\n",
    "        self.logitLayer.apply(init_weights)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.baseModel(inputs)\n",
    "        tau_logit = self.logitLayer(inputs)\n",
    "        return tau_logit\n",
    "\n",
    "\n",
    "class DESCN(nn.Module):\n",
    "    \"\"\"DESCN (Deep End-to-end Stochastic Causal Network)\"\"\"\n",
    "    def __init__(self, input_dim, share_dim, base_dim, do_rate, device, batch_norm=False, normalization=\"none\"):\n",
    "        super(DESCN, self).__init__()\n",
    "        # Конфигурация модели\n",
    "        cfg = {\n",
    "            'do_rate': do_rate,\n",
    "            'BatchNorm1d': 'true' if batch_norm else 'false',\n",
    "            'normalization': normalization\n",
    "        }\n",
    "        \n",
    "        # Компоненты модели\n",
    "        self.shareNetwork = ShareNetwork(input_dim, share_dim, base_dim, cfg, device)\n",
    "        self.prpsy_network = PrpsyNetwork(base_dim, cfg)\n",
    "        self.mu1_network = Mu1Network(base_dim, cfg)\n",
    "        self.mu0_network = Mu0Network(base_dim, cfg)\n",
    "        self.tau_network = TauNetwork(base_dim, cfg)\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        shared_h = self.shareNetwork(inputs)\n",
    "\n",
    "        # propensity output_logit\n",
    "        p_prpsy_logit = self.prpsy_network(shared_h)\n",
    "        p_prpsy = torch.clip(torch.sigmoid(p_prpsy_logit), 0.001, 0.999)\n",
    "\n",
    "        # logit for mu1, mu0\n",
    "        mu1_logit = self.mu1_network(shared_h)\n",
    "        mu0_logit = self.mu0_network(shared_h)\n",
    "\n",
    "        # pseudo tau\n",
    "        tau_logit = self.tau_network(shared_h)\n",
    "\n",
    "        p_mu1 = torch.sigmoid(mu1_logit)\n",
    "        p_mu0 = torch.sigmoid(mu0_logit)\n",
    "\n",
    "        # entire space\n",
    "        p_estr = torch.mul(p_prpsy, p_mu1)\n",
    "        p_i_prpsy = 1 - p_prpsy\n",
    "        p_escr = torch.mul(p_i_prpsy, p_mu0)\n",
    "        \n",
    "        # Рассчитываем аплифт (эффект воздействия)\n",
    "        uplift = p_mu1 - p_mu0\n",
    "        # uplift = p_estr - p_escr\n",
    "\n",
    "        return {\n",
    "            'p_prpsy_logit': p_prpsy_logit,\n",
    "            'p_estr': p_estr,\n",
    "            'p_escr': p_escr,\n",
    "            'tau_logit': tau_logit,\n",
    "            'mu1_logit': mu1_logit,\n",
    "            'mu0_logit': mu0_logit,\n",
    "            'p_prpsy': p_prpsy,\n",
    "            'p_mu1': p_mu1,\n",
    "            'p_mu0': p_mu0,\n",
    "            'shared_h': shared_h,\n",
    "            'uplift': uplift\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
