{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4af674c-4476-407a-9cbb-3075ad1ef74e",
   "metadata": {},
   "source": [
    "## Datasets processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25e21cb5-e492-49b6-b273-ce9629ead22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from src.distributions_check import check_feature_distributions_by_stat_test, check_feature_distributions_by_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1920573-623c-4b32-9d6d-41c3e52f8aa8",
   "metadata": {},
   "source": [
    "### Loading datasets from internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc2d4d-20f9-4ddb-90d6-f5f9f5d4223a",
   "metadata": {},
   "source": [
    "#### Criteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a1c7c-8608-46f3-a214-8021617db001",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/criteo/criteo-uplift https://www.uplift-modeling.com/en/latest/api/datasets/fetch_criteo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a9351a2-ef30-46c4-b52f-085acbf25b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hf://datasets/criteo/criteo-uplift/criteo-research-uplift-v2.1.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a65dfa-a43b-424f-b4f5-e8b00575dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030894610674129645 0.0019375880152813366\n",
      "0.036036727482199896 0.0\n",
      "0.048543360048743316 0.03820095691954503\n"
     ]
    }
   ],
   "source": [
    "print(df[df['treatment'] == 1]['conversion'].mean(), df[df['treatment'] == 0]['conversion'].mean())\n",
    "print(df[df['treatment'] == 1]['exposure'].mean(), df[df['treatment'] == 0]['exposure'].mean())\n",
    "print(df[df['treatment'] == 1]['visit'].mean(), df[df['treatment'] == 0]['visit'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d414bd72-42eb-43c3-9e6f-df439ceab02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "count_for_test = int(0.25 * len(df))\n",
    "train_data, test_data = train_test_split(df, test_size=count_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85547594-0afb-403c-9f12-04890dcc8bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Распределения похожи для всех фичей (p-value >= 0.05).\n"
     ]
    }
   ],
   "source": [
    "check_feature_distributions_by_stat_test(train_data, test_data, plot=False, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c79ab781-34e3-48e0-b279-3025af7e1efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.4986\n",
      "Тренировочные и тестовые датасеты РАЗЛИЧАЮТСЯ!\n"
     ]
    }
   ],
   "source": [
    "check_feature_distributions_by_model(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431901ab-09c8-4edc-8a02-3802756bd6c2",
   "metadata": {},
   "source": [
    "#### Lazada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d9980-df1a-4210-a2f6-6cc986ac8e2b",
   "metadata": {},
   "source": [
    "#### Lenta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360e1fe-680f-4794-bc15-4345bc91eef4",
   "metadata": {},
   "source": [
    "#### X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41777975-4cbf-44aa-a9bd-410f5bb80f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_features(self, percent, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Вычисляем количество фичей для выборки\n",
    "    n_features = self.train_data.shape[1]  # Количество колонок (фичей)\n",
    "    sampled_features = int(n_features * percent)  # Количество фичей для выборки\n",
    "\n",
    "    # Случайно выбираем индексы фичей\n",
    "    sampled_indices = np.random.permutation(n_features)[:sampled_features]\n",
    "\n",
    "    # Отбираем фичи в обеих выборках\n",
    "    train_sampled = self.train_data[:, sampled_indices]\n",
    "    test_sampled = self.test_data[:, sampled_indices]\n",
    "\n",
    "    # Сохраняем результат\n",
    "    train_out_path = os.path.join(output_dir, 'train.tsv')\n",
    "    test_out_path = os.path.join(output_dir, 'test.tsv')\n",
    "    pd.DataFrame(train_sampled).to_csv(train_out_path, sep='\\t', index=False, header=False)\n",
    "    pd.DataFrame(test_sampled).to_csv(test_out_path, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6555bf62-78c1-4f3d-8960-040c368deea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class IDataset(ABC):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "    # @abstractmethod\n",
    "    # def example(self):\n",
    "    #     \"\"\"Загружает данные\"\"\"\n",
    "    #     pass\n",
    "\n",
    "\n",
    "class TorchDataset(IDataset, Dataset):\n",
    "    def __init__(self, path):\n",
    "        IDataset.__init__(self)\n",
    "        Dataset.__init__(self)\n",
    "        self.data = torch.tensor(pd.read_csv(path, sep='\\t').values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class NumpyDataset(IDataset):\n",
    "    def __init__(self, path):\n",
    "        IDataset.__init__(self)\n",
    "        self.data = torch.tensor(pd.read_csv(path, sep='\\t').values, dtype=torch.float32)\n",
    "    def load(self, path):\n",
    "        \"\"\"Загружает данные в формате NumPy массивов\"\"\"\n",
    "        train_path = os.path.join(path, 'train.tsv')\n",
    "        test_path = os.path.join(path, 'test.tsv')\n",
    "\n",
    "        self.train_data = pd.read_csv(train_path, sep='\\t').values\n",
    "        self.test_data = pd.read_csv(test_path, sep='\\t').values\n",
    "\n",
    "    def sample_features(self, percent, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Вычисляем количество фичей для выборки\n",
    "        n_features = self.train_data.shape[1]  # Количество колонок (фичей)\n",
    "        sampled_features = int(n_features * percent)  # Количество фичей для выборки\n",
    "\n",
    "        # Случайно выбираем индексы фичей\n",
    "        sampled_indices = np.random.permutation(n_features)[:sampled_features]\n",
    "\n",
    "        # Отбираем фичи в обеих выборках\n",
    "        train_sampled = self.train_data[:, sampled_indices]\n",
    "        test_sampled = self.test_data[:, sampled_indices]\n",
    "\n",
    "        # Сохраняем результат\n",
    "        train_out_path = os.path.join(output_dir, 'train.tsv')\n",
    "        test_out_path = os.path.join(output_dir, 'test.tsv')\n",
    "        pd.DataFrame(train_sampled).to_csv(train_out_path, sep='\\t', index=False, header=False)\n",
    "        pd.DataFrame(test_sampled).to_csv(test_out_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Пример использования TorchDataset\n",
    "#     path_to_data = 'path_to_your_dataset_folder'  # Укажите путь к папке с данными\n",
    "#     output_directory = 'output_folder'  # Папка для сохранения выборок\n",
    "\n",
    "#     # TorchDataset: тренировка\n",
    "#     torch_dataset = TorchDataset(split='train')\n",
    "#     torch_dataset.load(path_to_data)\n",
    "#     torch_dataset.sample_features(0.5, output_directory)\n",
    "\n",
    "#     # TorchDataset: загрузка в DataLoader\n",
    "#     from torch.utils.data import DataLoader\n",
    "\n",
    "#     train_loader = DataLoader(torch_dataset, batch_size=32, shuffle=True)\n",
    "#     for batch in train_loader:\n",
    "#         print(batch)  # Вывод одного батча (примера)\n",
    "\n",
    "#     # Пример использования NumpyDataset\n",
    "#     numpy_dataset = NumpyDataset()\n",
    "#     numpy_dataset.load(path_to_data)\n",
    "#     numpy_dataset.sample_features(0.5, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0b226c-cb50-40d2-af2d-8911f4983358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
