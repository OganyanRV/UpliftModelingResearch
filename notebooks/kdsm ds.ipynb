{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d67b9a-3d69-44f9-bfda-6afa1e873069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    " \n",
    "if sys.argv:\n",
    "    sys.path.insert(0, str(pathlib.Path(os.path.dirname(os.path.abspath(\"\"))).resolve()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b329f-2b53-4614-a94c-011cfcb22a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src.global_params import COL_TARGET, COL_TREATMENT\n",
    "\n",
    "class IDataset(ABC):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "class TorchDataset(IDataset, Dataset):\n",
    "    def __init__(self, path):\n",
    "        IDataset.__init__(self)\n",
    "        Dataset.__init__(self)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pandas = pd.read_csv(path, sep='\\t')\n",
    "        self.data = torch.tensor(self.pandas.drop([COL_TREATMENT, COL_TARGET], axis=1).values, dtype=torch.float32).to(device)\n",
    "        self.target = torch.tensor(self.pandas[COL_TARGET].values, dtype=torch.float32).to(device)\n",
    "        self.treatment = torch.tensor(self.pandas[COL_TREATMENT].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77d484c0-3d57-417a-8021-064da459114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.datasets import IDataset, NumpyDataset\n",
    "import pickle\n",
    "class PairedUpliftDataset(IDataset, torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Датасет, содержащий пары примеров (treatment, control) с предсказаниями учителя.\n",
    "    \"\"\"\n",
    "    def __init__(self, teacher_model, path=None, from_saved_path=None):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "        teacher_model: Предобученная модель-учитель\n",
    "        \"\"\"\n",
    "        IDataset.__init__(self)\n",
    "        torch.utils.data.Dataset.__init__(self)\n",
    "\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        if from_saved_path:\n",
    "            self.load(from_saved_path)\n",
    "        else:\n",
    "            self.pandas = pd.read_csv(path, sep='\\t')\n",
    "            self.data = torch.tensor(self.pandas.drop([COL_TREATMENT, COL_TARGET], axis=1).values, dtype=torch.float32).to(self.device)\n",
    "            self.target = torch.tensor(self.pandas[COL_TARGET].values, dtype=torch.float32).to(self.device)\n",
    "            self.treatment = torch.tensor(self.pandas[COL_TREATMENT].values, dtype=torch.float32).to(self.device)\n",
    "    \n",
    "            # Разделяем примеры на группы воздействия и контроля\n",
    "            treatment_mask = self.treatment == 1\n",
    "            control_mask = self.treatment == 0\n",
    "            \n",
    "            self.treatment_indices = np.where(treatment_mask)[0]\n",
    "            self.control_indices = np.where(control_mask)[0]\n",
    "            \n",
    "            self.teacher_preds = torch.tensor(\n",
    "                teacher_model.predict(NumpyDataset(path))[\"score\"].values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "        \n",
    "        self.pairs = self._create_pairs()\n",
    "    \n",
    "    def _create_pairs(self):\n",
    "        \"\"\"\n",
    "        Создает пары из примеров групп воздействия и контроля.\n",
    "        \"\"\"\n",
    "        # Здесь мы используем случайное сопоставление примеров как в статье\n",
    "        \n",
    "        np.random.shuffle(self.treatment_indices)\n",
    "        np.random.shuffle(self.control_indices)\n",
    "        \n",
    "        n_pairs = min(len(self.treatment_indices), len(self.control_indices))\n",
    "        \n",
    "        pairs = [\n",
    "            (self.treatment_indices[i], self.control_indices[i])\n",
    "            for i in range(n_pairs)\n",
    "        ]\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        t_idx, c_idx = self.pairs[idx]\n",
    "        \n",
    "        # Извлекаем данные для примера из группы воздействия\n",
    "        t_features = self.data[t_idx]\n",
    "        t_treatment = self.treatment[t_idx]\n",
    "        t_outcome = self.target[t_idx]\n",
    "        t_teacher_pred = self.teacher_preds[t_idx]\n",
    "        \n",
    "        # Извлекаем данные для примера из контрольной группы\n",
    "        c_features = self.data[c_idx]\n",
    "        c_treatment = self.treatment[c_idx]\n",
    "        c_outcome = self.target[c_idx]\n",
    "        c_teacher_pred = self.teacher_preds[c_idx]\n",
    "        \n",
    "        return (t_features.to(self.device), t_treatment.to(self.device), t_outcome.to(self.device), t_teacher_pred.to(self.device),\n",
    "                c_features.to(self.device), c_treatment.to(self.device), c_outcome.to(self.device), c_teacher_pred.to(self.device))\n",
    "    \n",
    "    def shuffle_pairs(self):\n",
    "        \"\"\"\n",
    "        Вызывать перед новой эпохой для увеличения разнообразия пар.\n",
    "        \"\"\"\n",
    "        self.pairs = self._create_pairs()\n",
    "\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"\n",
    "        Сохраняет датасет в файл.\n",
    "        \"\"\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        \n",
    "        # Подготовка данных для сохранения\n",
    "        save_data = {\n",
    "            'data': self.data.cpu().numpy() if isinstance(self.data, torch.Tensor) else self.data,\n",
    "            'treatment': self.treatment.cpu().numpy() if isinstance(self.treatment, torch.Tensor) else self.treatment,\n",
    "            'target': self.target.cpu().numpy() if isinstance(self.target, torch.Tensor) else self.target,\n",
    "            'teacher_preds': self.teacher_preds.cpu().numpy() if isinstance(self.teacher_preds, torch.Tensor) else self.teacher_preds,\n",
    "            'treatment_indices': self.treatment_indices,\n",
    "            'control_indices': self.control_indices,\n",
    "            'pairs': self.pairs\n",
    "        }\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(save_data, f)\n",
    "        \n",
    "        print(f\"Dataset saved to {path}\")\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Загружает датасет из файла.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Dataset file not found: {path}\")\n",
    "        \n",
    "        # Загружаем данные из файла\n",
    "        with open(path, 'rb') as f:\n",
    "            load_data = pickle.load(f)\n",
    "        \n",
    "        # Восстанавливаем атрибуты\n",
    "        self.data = torch.tensor(load_data['data'], dtype=torch.float32)\n",
    "        self.treatment = torch.tensor(load_data['treatment'], dtype=torch.float32)\n",
    "        self.target = torch.tensor(load_data['target'], dtype=torch.float32)\n",
    "        self.teacher_preds = torch.tensor(load_data['teacher_preds'], dtype=torch.float32)\n",
    "        self.treatment_indices = load_data['treatment_indices']\n",
    "        self.control_indices = load_data['control_indices']\n",
    "        self.pairs = load_data['pairs']\n",
    "        \n",
    "        print(f\"Dataset loaded from {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ea87789-cc2d-4cca-bdb4-0702268dc961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /Users/ogrobertino/UpliftModelingResearch/exps2/lazada_v2/100/0/model.pkl.\n",
      "Config loaded from /Users/ogrobertino/UpliftModelingResearch/exps2/lazada_v2/100/0/config.json.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_paths_train_test, train_test_model\n",
    "from src.models.CausalML.Models import UpliftRandomForestModel\n",
    "from src.global_params import BASE_PATH\n",
    "model = UpliftRandomForestModel(from_load=True, path = BASE_PATH + \"/exps2/lazada_v2/100/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7f14bc-3690-4904-849b-095d29e9e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.models.CausalML.Models.UpliftRandomForestModel at 0x3476b0950>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61d0634-988a-4e4f-aad2-27426dfebdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'lazada_v2'\n",
    "features_percent = 100\n",
    "train_path, test_path = get_paths_train_test(ds_name=ds_name, features_percent=features_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78cdbbb4-f9b1-49e8-a45b-dcecc3c8184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_kdsm = PairedUpliftDataset(model, path = train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86916a57-db6a-4860-a78c-c93f5fc4d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /Users/ogrobertino/UpliftModelingResearch/data/lazada_v2_kdsm/train\n"
     ]
    }
   ],
   "source": [
    "ds_kdsm.save(BASE_PATH + \"/data/lazada_v2_kdsm/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0f4adbc-bd42-4e4e-86fa-a816fceb7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from /Users/ogrobertino/UpliftModelingResearch/data/lazada_v2_kdsm/train\n"
     ]
    }
   ],
   "source": [
    "ds_kdsm2 = PairedUpliftDataset(model, from_saved_path= BASE_PATH + \"/data/lazada_v2_kdsm/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d7ec23c-a377-4c1f-a017-2a25dee13755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PairedUpliftDataset at 0x348255550>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_kdsm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1dfe673b-b41d-45a5-897b-122c34fc82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    ds_kdsm2, \n",
    "    batch_size=1, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ace08613-0206-409e-9cd6-8767b171375a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000e+00,  1.6000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.6000e+02,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.0000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0206e-01,\n",
       "           1.2304e+00,  1.2304e+00,  1.2304e+00,  2.3000e+01,  0.0000e+00,\n",
       "           8.5907e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -6.2185e-01,  0.0000e+00,  1.3728e-02,\n",
       "          -1.2241e-01,  6.4896e-01,  0.0000e+00]]),\n",
       " tensor([1.]),\n",
       " tensor([0.]),\n",
       " tensor([0.0437]),\n",
       " tensor([[ 1.0000e+00,  8.6000e+01,  2.6912e+00,  0.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  2.6912e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  8.6000e+01,  1.7272e+00,  1.0000e+00,\n",
       "           9.8712e+00,  1.8222e+00,  0.0000e+00,  1.8222e+00,  2.8904e+00,\n",
       "           1.0000e+02,  8.1917e-01,  0.0000e+00,  2.8904e+00,  8.4510e-01,\n",
       "           2.0374e+00,  2.0374e+00,  2.0374e+00,  4.0000e+00,  0.0000e+00,\n",
       "           9.7505e-01,  1.4048e-01,  4.0450e-01,  0.0000e+00,  1.7500e+00,\n",
       "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.6094e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  3.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -6.2185e-01,  1.5000e+00,  1.3728e-02,\n",
       "          -1.2241e-01,  6.4896e-01,  2.6912e+00]]),\n",
       " tensor([0.]),\n",
       " tensor([0.]),\n",
       " tensor([0.0423])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e47331a1-abd0-4a0a-9225-415d875185b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = model.predict(NumpyDataset(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19349b52-1f19-4073-a2eb-3a5b1657e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0515, 0.0355, 0.0404,  ..., 0.0439, 0.0719, 0.0878],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(kek[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac9ceea4-2eb3-4259-8b5b-e2b6e87b7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(\n",
    "    ds_kdsm, \n",
    "    batch_size=1, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96193f0f-cd35-4beb-90a1-7b4812038052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ogrobertino/UpliftModelingResearch/exps2/lazada_v2_kdsm/train'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH + \"/exps2/lazada_v2_kdsm/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8489b3b9-7532-4e4d-838b-3e13198b37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1b0dc2f-e4a4-463f-acea-d47d7b9e24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000e+00,  3.6500e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.6500e+02,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9897e-01,\n",
       "          1.5682e+00,  1.5682e+00,  1.5682e+00,  1.7000e+01,  0.0000e+00,\n",
       "          9.2991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  2.0278e-02,  0.0000e+00, -1.0695e-02,\n",
       "         -2.2386e-02, -2.4405e-02,  0.0000e+00]),\n",
       " tensor(1.),\n",
       " tensor(0.),\n",
       " tensor(0.0189),\n",
       " tensor([ 2.0000e+00,  1.0900e+02,  1.3437e+00,  0.0000e+00,  6.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8904e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0900e+02,  0.0000e+00,  1.0000e+00,\n",
       "          9.8898e+00,  9.6577e-01,  0.0000e+00,  9.6577e-01,  0.0000e+00,\n",
       "          1.0000e+02,  1.9184e-01,  0.0000e+00,  2.1972e+00,  1.0414e+00,\n",
       "          1.8976e+00,  1.8976e+00,  1.8976e+00,  0.0000e+00,  0.0000e+00,\n",
       "          9.6590e-01,  4.3023e-01,  2.3962e-01,  0.0000e+00,  7.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          6.9315e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  3.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00, -6.2185e-01,  3.0000e+00,  1.3728e-02,\n",
       "         -1.2241e-01,  6.4896e-01,  2.8904e+00]),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.0635))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_kdsm[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
