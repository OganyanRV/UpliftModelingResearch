{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d67b9a-3d69-44f9-bfda-6afa1e873069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    " \n",
    "if sys.argv:\n",
    "    sys.path.insert(0, str(pathlib.Path(os.path.dirname(os.path.abspath(\"\"))).resolve()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b329f-2b53-4614-a94c-011cfcb22a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from src.global_params import COL_TARGET, COL_TREATMENT\n",
    "\n",
    "class IDataset(ABC):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "class TorchDataset(IDataset, Dataset):\n",
    "    def __init__(self, path):\n",
    "        IDataset.__init__(self)\n",
    "        Dataset.__init__(self)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pandas = pd.read_csv(path, sep='\\t')\n",
    "        self.data = torch.tensor(self.pandas.drop([COL_TREATMENT, COL_TARGET], axis=1).values, dtype=torch.float32).to(device)\n",
    "        self.target = torch.tensor(self.pandas[COL_TARGET].values, dtype=torch.float32).to(device)\n",
    "        self.treatment = torch.tensor(self.pandas[COL_TREATMENT].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77d484c0-3d57-417a-8021-064da459114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.datasets import IDataset, NumpyDataset\n",
    "class PairedUpliftDataset(IDataset, torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Датасет, содержащий пары примеров (treatment, control) с предсказаниями учителя.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, teacher_model):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "        teacher_model: Предобученная модель-учитель\n",
    "        \"\"\"\n",
    "        IDataset.__init__(self)\n",
    "        torch.utils.data.Dataset.__init__(self)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pandas = pd.read_csv(path, sep='\\t')\n",
    "        self.data = torch.tensor(self.pandas.drop([COL_TREATMENT, COL_TARGET], axis=1).values, dtype=torch.float32).to(device)\n",
    "        self.target = torch.tensor(self.pandas[COL_TARGET].values, dtype=torch.float32).to(device)\n",
    "        self.treatment = torch.tensor(self.pandas[COL_TREATMENT].values, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Разделяем примеры на группы воздействия и контроля\n",
    "        treatment_mask = self.treatment == 1\n",
    "        control_mask = self.treatment == 0\n",
    "        \n",
    "        self.treatment_indices = np.where(treatment_mask)[0]\n",
    "        self.control_indices = np.where(control_mask)[0]\n",
    "        \n",
    "        self.teacher_preds = torch.tensor(\n",
    "            teacher_model.predict(NumpyDataset(path))[\"score\"].values,\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        self.pairs = self._create_pairs()\n",
    "    \n",
    "    def _create_pairs(self):\n",
    "        \"\"\"\n",
    "        Создает пары из примеров групп воздействия и контроля.\n",
    "        \"\"\"\n",
    "        # Здесь мы используем случайное сопоставление примеров как в статье\n",
    "        \n",
    "        np.random.shuffle(self.treatment_indices)\n",
    "        np.random.shuffle(self.control_indices)\n",
    "        \n",
    "        n_pairs = min(len(self.treatment_indices), len(self.control_indices))\n",
    "        \n",
    "        pairs = [\n",
    "            (self.treatment_indices[i], self.control_indices[i])\n",
    "            for i in range(n_pairs)\n",
    "        ]\n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        t_idx, c_idx = self.pairs[idx]\n",
    "        \n",
    "        # Извлекаем данные для примера из группы воздействия\n",
    "        t_features = self.data[t_idx]\n",
    "        t_treatment = self.treatment[t_idx]\n",
    "        t_outcome = self.target[t_idx]\n",
    "        t_teacher_pred = self.teacher_preds[t_idx]\n",
    "        \n",
    "        # Извлекаем данные для примера из контрольной группы\n",
    "        c_features = self.data[c_idx]\n",
    "        c_treatment = self.treatment[c_idx]\n",
    "        c_outcome = self.target[c_idx]\n",
    "        c_teacher_pred = self.teacher_preds[c_idx]\n",
    "        \n",
    "        return (t_features.to(device), t_treatment.to(device), t_outcome.to(device), t_teacher_pred.to(device),\n",
    "                c_features.to(device), c_treatment.to(device), c_outcome.to(device), c_teacher_pred.to(device))\n",
    "    \n",
    "    def shuffle_pairs(self):\n",
    "        \"\"\"\n",
    "        Вызывать перед новой эпохой для увеличения разнообразия пар.\n",
    "        \"\"\"\n",
    "        self.pairs = self._create_pairs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cbeaa-645e-454b-9680-a074b4e2104a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea87789-cc2d-4cca-bdb4-0702268dc961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /Users/ogrobertino/UpliftModelingResearch/exps2/lazada_v2/100/0/model.pkl.\n",
      "Config loaded from /Users/ogrobertino/UpliftModelingResearch/exps2/lazada_v2/100/0/config.json.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_paths_train_test, train_test_model\n",
    "from src.models.CausalML.Models import UpliftRandomForestModel\n",
    "from src.global_params import BASE_PATH\n",
    "model = UpliftRandomForestModel(from_load=True, path = BASE_PATH + \"/exps2/lazada_v2/100/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7f14bc-3690-4904-849b-095d29e9e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.models.CausalML.Models.UpliftRandomForestModel at 0x3476b0950>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61d0634-988a-4e4f-aad2-27426dfebdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'lazada_v2'\n",
    "features_percent = 100\n",
    "train_path, test_path = get_paths_train_test(ds_name=ds_name, features_percent=features_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78cdbbb4-f9b1-49e8-a45b-dcecc3c8184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_kdsm = PairedUpliftDataset(train_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e47331a1-abd0-4a0a-9225-415d875185b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = model.predict(NumpyDataset(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19349b52-1f19-4073-a2eb-3a5b1657e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0515, 0.0355, 0.0404,  ..., 0.0439, 0.0719, 0.0878],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(kek[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac9ceea4-2eb3-4259-8b5b-e2b6e87b7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(\n",
    "    ds_kdsm, \n",
    "    batch_size=1, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8489b3b9-7532-4e4d-838b-3e13198b37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a79d7536-d9c0-4b51-ae6d-3158a98079b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.0000e+00,  9.0000e+01,  3.7728e+00,  0.0000e+00,  2.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4543e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  9.0000e+01,  0.0000e+00,  1.0000e+00,\n",
       "           1.0137e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.0000e+02,  6.5033e-02,  0.0000e+00,  1.9459e+00,  9.5424e-01,\n",
       "           1.7709e+00,  1.7709e+00,  1.7709e+00,  1.2000e+01,  0.0000e+00,\n",
       "           9.5486e-01,  0.0000e+00,  7.5317e-02,  0.0000e+00,  2.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  2.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  5.6092e-02,  2.0000e+00, -6.1764e-03,\n",
       "          -1.2315e-02,  9.9352e-02,  4.4543e+00]]),\n",
       " tensor([1.]),\n",
       " tensor([0.]),\n",
       " tensor([0.0456]),\n",
       " tensor([[ 5.0000e+00,  1.6800e+02,  3.5361e+00,  3.3322e+00,  2.7500e+00,\n",
       "           3.0000e+00,  9.4039e-01,  1.6435e+00,  4.4471e+00,  2.0334e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.6800e+02,  0.0000e+00,  1.0000e+00,\n",
       "           1.0376e+01,  5.7942e+00,  3.8286e+00,  5.7942e+00,  1.9459e+00,\n",
       "           1.1000e+01,  3.3197e-01,  0.0000e+00,  3.1355e+00,  1.0414e+00,\n",
       "           2.3909e+00,  2.3909e+00,  2.3909e+00,  3.0000e+00,  0.0000e+00,\n",
       "           9.8879e-01,  1.4048e-01,  2.3962e-01,  9.4039e-01,  1.5250e+01,\n",
       "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           1.3863e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  1.6435e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00,  5.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "           1.0000e+00,  0.0000e+00, -6.2185e-01,  2.7500e+00,  1.3728e-02,\n",
       "          -1.2241e-01,  6.4896e-01,  4.6396e+00]]),\n",
       " tensor([0.]),\n",
       " tensor([0.]),\n",
       " tensor([0.0639])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1b0dc2f-e4a4-463f-acea-d47d7b9e24c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000e+00,  3.6500e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  3.6500e+02,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9897e-01,\n",
       "          1.5682e+00,  1.5682e+00,  1.5682e+00,  1.7000e+01,  0.0000e+00,\n",
       "          9.2991e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  2.0278e-02,  0.0000e+00, -1.0695e-02,\n",
       "         -2.2386e-02, -2.4405e-02,  0.0000e+00]),\n",
       " tensor(1.),\n",
       " tensor(0.),\n",
       " tensor(0.0189),\n",
       " tensor([ 2.0000e+00,  1.0900e+02,  1.3437e+00,  0.0000e+00,  6.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.8904e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0900e+02,  0.0000e+00,  1.0000e+00,\n",
       "          9.8898e+00,  9.6577e-01,  0.0000e+00,  9.6577e-01,  0.0000e+00,\n",
       "          1.0000e+02,  1.9184e-01,  0.0000e+00,  2.1972e+00,  1.0414e+00,\n",
       "          1.8976e+00,  1.8976e+00,  1.8976e+00,  0.0000e+00,  0.0000e+00,\n",
       "          9.6590e-01,  4.3023e-01,  2.3962e-01,  0.0000e+00,  7.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          6.9315e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  3.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00, -6.2185e-01,  3.0000e+00,  1.3728e-02,\n",
       "         -1.2241e-01,  6.4896e-01,  2.8904e+00]),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.0635))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_kdsm[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
