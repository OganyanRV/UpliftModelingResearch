{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686ed201-9056-4c1a-a6f3-1d5691dc6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    " \n",
    "if sys.argv:\n",
    "    sys.path.insert(0, str(Path('/Users/ogrobertino/UpliftModelingResearch/').resolve()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from src.datasets import sample_features, TorchDataset, NumpyDataset\n",
    "from src.global_params import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "163b375b-9b98-4c4a-ab0e-24db1601ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import causalml\n",
    "import causalml.metrics as cmetrics\n",
    "import causalml.inference.tree as ctree\n",
    "import causalml.inference.meta.tlearner as tlearner\n",
    "import causalml.inference.meta.slearner as slearner\n",
    "import causalml.inference.meta.rlearner as rlearner\n",
    "import causalml.inference.meta.xlearner as xlearner\n",
    "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
    "\n",
    "\n",
    "class IModelUplift(ABC):\n",
    "    \"\"\"\n",
    "    Интерфейс для реализации моделей uplift.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_json=None, from_load=False, path=None):\n",
    "        if from_load == False:\n",
    "            if config_json is None:\n",
    "                raise ValueError(f\"No config while contstructing model.\")\n",
    "            self.model = None\n",
    "            self.config = config_json\n",
    "        else:\n",
    "            if path is None:\n",
    "                raise ValueError(f\"No config or model paths while contstructing model.\")\n",
    "            # Дебильный баг, что если сделать self.moldel=loaded_model то models_t, models_s не будут внутри self.model\n",
    "            model, config = self.load(path)\n",
    "\n",
    "            self.model = model\n",
    "            self.config = config\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод для обучения модели.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Метод для предсказания.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        Метод для загрузки обученной модели из файла.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class ICausalML(IModelUplift):\n",
    "    def __init__(self, config_json=None, from_load=False, path=None):\n",
    "        super().__init__(config_json, from_load, path)\n",
    "\n",
    "    def fit(self, train):\n",
    "        self.model.fit(\n",
    "            X=train.data.loc[:, train.cols_features].values,\n",
    "            treatment=train.data.loc[:, train.col_treatment].values,\n",
    "            y=train.data.loc[:, train.col_target].values,\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = X.data.copy(deep=True)\n",
    "        scores['score'] = self.model.predict(scores.loc[:, X.cols_features])\n",
    "        return scores[['score', X.col_treatment, X.col_target]]\n",
    "\n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f\"Model saved to {path}.\")\n",
    "\n",
    "    def load(self, path):\n",
    "        config_path = path + \"/config.json\" \n",
    "        model_path = path + \"/model.pkl\"\n",
    "        if not os.path.exists(config_path):\n",
    "            raise ValueError(f\"No file found at '{config_path}'.\")\n",
    "        if not os.path.exists(model_path):\n",
    "            raise ValueError(f\"No file found at '{model_path}'.\")\n",
    "        \n",
    "        with open(model_path, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "        with open(config_path, 'rb') as f:\n",
    "            loaded_config = json.load(f)\n",
    "            \n",
    "        print(f\"Model loaded from {model_path}.\")\n",
    "        print(f\"Config loaded from {config_path}.\")\n",
    "\n",
    "        return loaded_model, loaded_config\n",
    "\n",
    "# Конкретная реализация модели\n",
    "class TModel(ICausalML):\n",
    "    \"\"\"\n",
    "    t-моделинг с помощью causalml.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config_json=None, from_load=False, path=None):\n",
    "        super().__init__(config_json, from_load, path)\n",
    "        self.model = tlearner.BaseTClassifier(\n",
    "            control_learner=CatBoostClassifier(verbose=0, **self.config['lvl_1']['control']),\n",
    "            treatment_learner=CatBoostClassifier(verbose=0, **self.config['lvl_1']['treatment']),\n",
    "            **self.config['lvl_0']['meta']\n",
    "        )\n",
    "\n",
    "def ModelUpliftFactory(config_json, model_class):\n",
    "    \"\"\"\n",
    "    Фабрика для создания экземпляра модели uplift.\n",
    "\n",
    "    :param config_json: JSON-строка с конфигурацией модели.\n",
    "    :param model_class: Класс, реализующий интерфейс ModelUplift.\n",
    "    \"\"\"\n",
    "    if not issubclass(model_class, ModelUplift):\n",
    "        raise ValueError(\"model_class должен быть подклассом ModelUplift.\")\n",
    "    \n",
    "    return model_class(config_json)\n",
    "\n",
    "class IFactory(ABC):\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def create():\n",
    "        \"\"\"Фабричный метод, создающий объект модели и датасета.\"\"\"\n",
    "        pass\n",
    "\n",
    "class TModelFactory(IFactory):\n",
    "    @staticmethod\n",
    "    def create(config_json, train_path, test_path):\n",
    "        model = TModel(config_json)\n",
    "        train = NumpyDataset(train_path)\n",
    "        test = NumpyDataset(test_path)\n",
    "        return model, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67853a15-aa37-474a-a8ae-cdc95349fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, train, test = TModelFactory.create(config, path_train, path_test)\n",
    "# model.fit(train)\n",
    "# predicted = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86251483-ce4a-4aca-8dc5-6b1ee3754bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmetrics.auuc_score(\n",
    "#     predicted, \n",
    "#     outcome_col=col_target, \n",
    "#     treatment_col=col_treatment, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103f2504-d8fa-467a-84d6-0d106e74b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_auuc, random_auuc = cmetrics.auuc_score(\n",
    "#     predicted, \n",
    "#     outcome_col=col_target, \n",
    "#     treatment_col=col_treatment, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b878d3d-6df6-4246-bd42-743fd0131664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmetrics.plot_gain(\n",
    "#     predicted,\n",
    "#     treatment_col=col_treatment,\n",
    "#     outcome_col=col_target,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764b3c11-d6e9-4dd8-a3fe-2983f780e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_train_test(ds_name, features_percent):\n",
    "\n",
    "    path_to_data_train = f'../data/{ds_name}/{features_percent}/train.tsv'\n",
    "    path_to_data_test = f'../data/{ds_name}/{features_percent}/test.tsv'\n",
    "\n",
    "    return path_to_data_train, path_to_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f3c23a-466e-4447-b814-c440ce61d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO outpath\n",
    "def train_test_model(ds_name, features_percent, factory, config):\n",
    "    train_path, test_path = get_paths_train_test(ds_name=ds_name, features_percent=features_percent)\n",
    "    model, train, test = factory.create(config, train_path, test_path)\n",
    "    model.fit(train)\n",
    "    predicted = model.predict(test)\n",
    "\n",
    "    return model, predicted\n",
    "    ml_auuc, random_auuc = cmetrics.auuc_score(\n",
    "        predicted, \n",
    "        outcome_col=col_target, \n",
    "        treatment_col=col_treatment, \n",
    "    )\n",
    "\n",
    "    \n",
    "    print(ml_auuc, random_auuc)\n",
    "    cmetrics.plot_gain(\n",
    "        predicted,\n",
    "        treatment_col=col_treatment,\n",
    "        outcome_col=col_target,\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3f1bd1-b488-4c80-a10d-49154dadee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \\\n",
    "{\n",
    "  \"lvl_0\": {\n",
    "    \"meta\": {\n",
    "      \"control_name\": 0\n",
    "    }\n",
    "  },\n",
    "  \"lvl_1\": {\n",
    "    \"treatment\": {\n",
    "      \"iterations\": 20,\n",
    "      \"learning_rate\": 0.1,\n",
    "      \"depth\": 6,\n",
    "      \"loss_function\": \"Logloss\",\n",
    "      \"eval_metric\": \"AUC\"\n",
    "    },\n",
    "    \"control\": {\n",
    "      \"iterations\": 30,\n",
    "      \"learning_rate\": 0.05,\n",
    "      \"depth\": 4,\n",
    "      \"loss_function\": \"Logloss\",\n",
    "      \"eval_metric\": \"AUC\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145aba12-bae8-43a2-b908-a765e53084a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, test_path = get_paths_train_test(ds_name='lazada', features_percent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbbc474-e000-44eb-88d6-d9deb55c7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, predicted = train_test_model(ds_name='lazada', features_percent=100, factory=TModelFactory, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d3c701-381d-459d-b3c5-689c752e0131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181664</th>\n",
       "      <td>0.056568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181665</th>\n",
       "      <td>0.063529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181666</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181667</th>\n",
       "      <td>0.007119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181668</th>\n",
       "      <td>0.045634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           score  treatment  target\n",
       "0       0.045564          1       0\n",
       "1       0.055329          0       0\n",
       "2       0.022363          0       0\n",
       "3       0.010221          1       0\n",
       "4       0.012022          0       0\n",
       "...          ...        ...     ...\n",
       "181664  0.056568          1       1\n",
       "181665  0.063529          1       0\n",
       "181666  0.010840          1       0\n",
       "181667  0.007119          1       0\n",
       "181668  0.045634          0       0\n",
       "\n",
       "[181669 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f635c7e-f5ab-4de7-81e3-46035dd59745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lvl_0': {'meta': {'control_name': 0}},\n",
       " 'lvl_1': {'treatment': {'iterations': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'depth': 6,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'},\n",
       "  'control': {'iterations': 30,\n",
       "   'learning_rate': 0.05,\n",
       "   'depth': 4,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cf3475b-1378-46a5-a2b9-315dcc8bd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from typing import Any\n",
    "\n",
    "def _write_files_(model: IModelUplift, predictions, ds_name, features_percent):\n",
    "    \"\"\"\n",
    "    Метод создает папку в нужной директории и записывает туда бинарик модели, предикты модели и конфиг.\n",
    "    \"\"\"\n",
    "\n",
    "    path_overall_stats = \"../exps\" \n",
    "    \n",
    "    free_folder_number = 0\n",
    "    os.makedirs(f'../exps/{ds_name}', exist_ok=True)\n",
    "    os.makedirs(f'../exps/{ds_name}/{features_percent}', exist_ok=True)        \n",
    "    while os.path.exists(os.path.join(f'../exps/{ds_name}/{features_percent}', str(free_folder_number))):\n",
    "        free_folder_number += 1\n",
    "    path_current_setup = f'../exps/{ds_name}/{features_percent}/{free_folder_number}'    \n",
    "    os.makedirs(path_current_setup, exist_ok=True)\n",
    "\n",
    "    # Сохранение модели\n",
    "    model_path = os.path.join(path_current_setup, \"model.pkl\")\n",
    "    with open(model_path, \"wb\") as model_file:\n",
    "        pickle.dump(model.model, model_file)\n",
    "\n",
    "    # Сохранение предсказаний\n",
    "    predictions_path = os.path.join(path_current_setup, \"predictions.tsv\")\n",
    "    predictions.to_csv(predictions_path)\n",
    "\n",
    "    # Сохранение конфига\n",
    "    config_path = os.path.join(path_current_setup, \"config.json\")\n",
    "    with open(config_path, \"w\") as config_file:\n",
    "        json.dump(model.config, config_file)\n",
    "\n",
    "    return path_current_setup\n",
    "\n",
    "\n",
    "def write(model: IModelUplift, predictions, ds_name, features_percent):\n",
    "    \"\"\"\n",
    "    Метод создает папку с первым свободным числом внутри папки с названием датасета,\n",
    "    куда сохраняет модель, предсказания, конфиг, метрики и тп.\n",
    "    \"\"\"\n",
    "    path_current_setup = _write_files_(model, predictions, ds_name, features_percent)\n",
    "    print(f\"Модель, предсказания и конфиг сохранены в директории {path_current_setup}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c442b56-5b4b-44bd-acb2-2ccceae3d890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель, предсказания и конфиг сохранены в директории ../exps/lazada/100/0\n"
     ]
    }
   ],
   "source": [
    "write(model, predicted, ds_name='lazada', features_percent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "519a67bf-f59f-4a37-a78d-7f3771dd11d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../exps/lazada/100/0/model.pkl.\n",
      "Config loaded from ../exps/lazada/100/0/config.json.\n"
     ]
    }
   ],
   "source": [
    "model2 = TModel(from_load=True, path=\"../exps/lazada/100/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94db0fb2-25b3-443c-935c-ea881b97eaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Метод для загрузки обученной модели из файла.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/config.json\"\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/model.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No file found at '{config_path}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No file found at '{model_path}'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloaded_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model loaded from {model_path}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Config loaded from {config_path}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /var/folders/2h/f3088zln2y36htvcq0wjvt94_1rc11/T/ipykernel_94019/1382219765.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.load??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6be9090d-76ca-4f1c-bc84-3df28cc70761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load2(path):\n",
    "    config_path = path + \"/config.json\" \n",
    "    model_path = path + \"/model.pkl\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise ValueError(f\"No file found at '{config_path}'.\")\n",
    "    if not os.path.exists(model_path):\n",
    "        raise ValueError(f\"No file found at '{model_path}'.\")\n",
    "    \n",
    "    with open(model_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    with open(config_path, 'rb') as f:\n",
    "        loaded_config = json.load(f)\n",
    "        \n",
    "    print(f\"Model loaded from {model_path}.\")\n",
    "    print(f\"Config loaded from {config_path}.\")\n",
    "\n",
    "    return loaded_model, loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "137b2e9e-21d1-4c67-aaa3-fd920f6815ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../exps/lazada/100/0/model.pkl.\n",
      "Config loaded from ../exps/lazada/100/0/config.json.\n"
     ]
    }
   ],
   "source": [
    "model3, _ = load2(\"../exps/lazada/100/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "77264c1c-a5c3-4520-bbda-5a30530de7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'Logloss': 0.20083979341393296}}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.models_t[1].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9840eb50-2c4f-4c89-bea1-ed8607b19e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <catboost.core.CatBoostClassifier at 0x3416d22d0>}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.models_c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19ce8bee-31e1-40d6-8b10-5ad3f9a532f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.model.model_t.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70701bb2-ce3c-4cb5-b7ca-307cf705c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "63a86db5-7f17-4f01-8ceb-ebc0988f2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = pickle.load(open(\"../exps/lazada/100/0/model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "21afe84a-5fb4-4adc-bbf4-c1ec7b706dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <catboost.core.CatBoostClassifier at 0x3bcb74fd0>}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.models_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80518ad-4fc0-42cc-a50a-2a5ce1842d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48a6a1fe-a024-474f-b4be-20ad7e5f4c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>treatment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181664</th>\n",
       "      <td>0.056568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181665</th>\n",
       "      <td>0.063529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181666</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181667</th>\n",
       "      <td>0.007119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181668</th>\n",
       "      <td>0.045634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           score  treatment  target\n",
       "0       0.045564          1       0\n",
       "1       0.055329          0       0\n",
       "2       0.022363          0       0\n",
       "3       0.010221          1       0\n",
       "4       0.012022          0       0\n",
       "...          ...        ...     ...\n",
       "181664  0.056568          1       1\n",
       "181665  0.063529          1       0\n",
       "181666  0.010840          1       0\n",
       "181667  0.007119          1       0\n",
       "181668  0.045634          0       0\n",
       "\n",
       "[181669 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb1e09-f023-4204-af74-39f93b7366b8",
   "metadata": {},
   "source": [
    "   * Назваине модели/класса (. __ class __)\n",
    "   * Конфиг (гиперпараметры)\n",
    "   * Название датасета\n",
    "   * Процент фичей\n",
    "   * Путь до бинаря модели\n",
    "   * Время работы (latency)\n",
    "   * Размер бинаря?\n",
    "   * AUUC на тесте\n",
    "   * precision@[5, 100] на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdeb11cc-3c20-4f9e-994e-bb3c730e93da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053735"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(\"model.pkl\") / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6880e3-f64c-433f-9c00-92a93273deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\n",
    "    'Model',\n",
    "    'Path',\n",
    "    'Dataset',\n",
    "    'Features Percent',\n",
    "    'Latency',\n",
    "    'Binary Size (MB)',\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabfa87-fdbd-4ba4-b2e7-1047f5168a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model: Callable, data: pd.DataFrame, batch_size: int = 32) -> float:\n",
    "    \"\"\"\n",
    "    Функция для измерения среднего времени инференса модели на данных в виде батчей.\n",
    "    \n",
    "    :param model: Callable (модель или функция с методом `predict` или аналогичным)\n",
    "    :param data: pd.DataFrame (входные данные для инференса)\n",
    "    :param batch_size: int (Размер батча для инференса)\n",
    "    :return: Среднее время инференса одного батча в миллисекундах\n",
    "    \"\"\"\n",
    "    # Разделение данных на батчи\n",
    "    batches = [\n",
    "        data.iloc[i:i + batch_size]\n",
    "        for i in range(0, len(data), batch_size)\n",
    "    ]\n",
    "\n",
    "    # Список для хранения времени инференса каждого батча\n",
    "    inference_times = []\n",
    "\n",
    "    for batch in batches:\n",
    "        start_time = time.time()  # Замер начала времени\n",
    "        predictions = model.predict(batch)  # Инференс модели\n",
    "        end_time = time.time()  # Замер окончания времени\n",
    "        \n",
    "        # Добавляем время инференса текущего батча в список (в миллисекундах)\n",
    "        inference_times.append((end_time - start_time) * 1000)\n",
    "\n",
    "    # Рассчет среднего времени инференса на один батч\n",
    "    mean_inference_time = np.mean(inference_times)\n",
    "    \n",
    "    print(f\"Среднее время инференса одного батча: {mean_inference_time:.2f} ms\")\n",
    "    return mean_inference_time\n",
    "\n",
    "\n",
    "# Пример модели с методом `predict`\n",
    "class DummyModel:\n",
    "    def predict(self, data_batch):\n",
    "        # Эмуляция обработки данными (например, sleep на 10 мс)\n",
    "        time.sleep(0.01)\n",
    "        return np.random.rand(len(data_batch), 1)  # Возвращаем рандомные предсказания\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Создаем фиктивный DataFrame для демонстрации\n",
    "    num_samples = 1000\n",
    "    num_features = 10\n",
    "    dummy_data = pd.DataFrame(np.random.rand(num_samples, num_features), columns=[f\"feature_{i}\" for i in range(num_features)])\n",
    "    \n",
    "    # Создаем модель\n",
    "    model = DummyModel()\n",
    "\n",
    "    # Замеряем среднее время инференса\n",
    "    average_time = measure_inference_time(model, dummy_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0267e686-b1d3-448a-87d4-9d0f284f07e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel/Class\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config,\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdataset_name\u001b[49m,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures Percent\u001b[39m\u001b[38;5;124m\"\u001b[39m: features_percent,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Path\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_binary_path,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatency (ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m: latency,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary Size (KB)\u001b[39m\u001b[38;5;124m\"\u001b[39m: binary_size,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUUC (test)\u001b[39m\u001b[38;5;124m\"\u001b[39m: auuc_test,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision@[5,100]\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision_at_k\n\u001b[1;32m     11\u001b[0m     }])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_name' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame([{\n",
    "        \"Model/Class\": model.__class__.__name__,\n",
    "        \"Config\": config,\n",
    "        \"Dataset Name\": dataset_name,\n",
    "        \"Features Percent\": features_percent,\n",
    "        \"Model Path\": model_binary_path,\n",
    "        \"Latency (ms)\": latency,\n",
    "        \"Binary Size (KB)\": binary_size,\n",
    "        \"AUUC (test)\": auuc_test,\n",
    "        \"Precision@[5,100]\": precision_at_k\n",
    "    }])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
