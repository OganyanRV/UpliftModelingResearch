{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb3f98b-7f15-45dd-af85-16234d7798e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    " \n",
    "if sys.argv:\n",
    "    sys.path.insert(0, str(Path('/Users/ogrobertino/UpliftModelingResearch/').resolve()))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0098d1d6-36f6-4608-b0ed-75c2d5ffec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_paths_train_test, train_test_model\n",
    "from src.factory import TModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66739283-6518-45a6-8f1f-9cd84cbd240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab29ed-a8dd-46ff-ae7c-a200290e8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(count), desc=\"Generating configs\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f1fe0c0-53c2-46be-9643-9e55495112bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4590574-5246-4981-9c45-248b63ec7e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../exps/lazada/100/0'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pd.read_csv('../exps/stats.tsv', sep='\\t').sort_values('AUUC (test)', ascending=False).Path.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16060525-e264-471d-bb3c-ff1aca368cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ICausalML.Models import TModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01f297d8-2fe7-4b4c-ad18-07dc45ffa1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../exps/lazada/100/1/model.pkl.\n",
      "Config loaded from ../exps/lazada/100/1/config.json.\n"
     ]
    }
   ],
   "source": [
    "best_model = TModel(from_load=True, path=pd.read_csv('../exps/stats.tsv', sep='\\t').sort_values('AUUC (test)', ascending=False).Path.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7bc61f88-b1de-46a9-9046-030075dc9ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Path</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Features Percent</th>\n",
       "      <th>Latency (ms)</th>\n",
       "      <th>Binary Size (MB)</th>\n",
       "      <th>AUUC (test)</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Precision@15</th>\n",
       "      <th>Precision@20</th>\n",
       "      <th>Precision@25</th>\n",
       "      <th>Precision@50</th>\n",
       "      <th>Compressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TModel</td>\n",
       "      <td>../exps/lazada/100/1</td>\n",
       "      <td>lazada</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>8.574377</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TModel</td>\n",
       "      <td>../exps/lazada/100/0</td>\n",
       "      <td>lazada</td>\n",
       "      <td>100</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.053735</td>\n",
       "      <td>0.719271</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model                  Path Dataset  Features Percent  Latency (ms)  \\\n",
       "1  TModel  ../exps/lazada/100/1  lazada               100      0.059375   \n",
       "0  TModel  ../exps/lazada/100/0  lazada               100      0.057778   \n",
       "\n",
       "   Binary Size (MB)  AUUC (test)  Precision@5  Precision@10  Precision@15  \\\n",
       "1          8.574377     0.502273    -0.001187      0.006886      0.006594   \n",
       "0          0.053735     0.719271     0.003331      0.009578      0.009491   \n",
       "\n",
       "   Precision@20  Precision@25  Precision@50 Compressions  \n",
       "1      0.006886      0.006587      0.004062           {}  \n",
       "0      0.009578      0.007752      0.006447           {}  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('../exps/stats.tsv', sep='\\t').sort_values('AUUC (test)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e755c7a-f556-424f-b58d-922d5f266d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating configs: 100%|██████████████████████████████████████████████████████| 5/5 [00:00<00:00, 49932.19it/s]\n"
     ]
    }
   ],
   "source": [
    "configs = generate_random_configs_tmodel(treatment_parameters, control_parameters, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a982b09b-c81d-4a7e-9b19-f80a799c71de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель, предсказания и конфиг сохранены в директории ../exps/lazada/100/1\n",
      "Эксперимент сохранен в таблице ../exps/stats.tsv\n"
     ]
    }
   ],
   "source": [
    "train_test_model(ds_name='lazada', features_percent=100, factory=TModelFactory, config=configs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc020a6f-b525-4c20-921e-0ff8c5ffda76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Config 1:\n",
      "{'lvl_0': {'meta': {'control_name': 0}}, 'lvl_1': {'treatment': {'iterations': 16, 'learning_rate': 0.324, 'depth': 10, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}, 'control': {'iterations': 95, 'learning_rate': 0.498, 'depth': 8, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}}}\n",
      "\n",
      "\n",
      "Random Config 2:\n",
      "{'lvl_0': {'meta': {'control_name': 0}}, 'lvl_1': {'treatment': {'iterations': 28, 'learning_rate': 0.49, 'depth': 10, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}, 'control': {'iterations': 17, 'learning_rate': 0.197, 'depth': 1, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}}}\n",
      "\n",
      "\n",
      "Random Config 3:\n",
      "{'lvl_0': {'meta': {'control_name': 0}}, 'lvl_1': {'treatment': {'iterations': 16, 'learning_rate': 0.378, 'depth': 5, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}, 'control': {'iterations': 17, 'learning_rate': 0.416, 'depth': 2, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}}}\n",
      "\n",
      "\n",
      "Random Config 4:\n",
      "{'lvl_0': {'meta': {'control_name': 0}}, 'lvl_1': {'treatment': {'iterations': 89, 'learning_rate': 0.206, 'depth': 8, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}, 'control': {'iterations': 10, 'learning_rate': 0.302, 'depth': 2, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}}}\n",
      "\n",
      "\n",
      "Random Config 5:\n",
      "{'lvl_0': {'meta': {'control_name': 0}}, 'lvl_1': {'treatment': {'iterations': 92, 'learning_rate': 0.132, 'depth': 3, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}, 'control': {'iterations': 58, 'learning_rate': 0.496, 'depth': 9, 'loss_function': 'Logloss', 'eval_metric': 'AUC'}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Задаем диапазоны для параметров лечения и контроля\n",
    "\n",
    "\n",
    "# Генерация 5 случайных конфигураций\n",
    "for i in range(5):\n",
    "    random_config = generate_random_config(treatment_parameters, control_parameters)\n",
    "    print(f\"Random Config {i+1}:\")\n",
    "    print(random_config)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40df88d-9fac-423c-9f2d-4394b486141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lvl_0': {'meta': {'control_name': 0}},\n",
       " 'lvl_1': {'treatment': {'iterations': 92,\n",
       "   'learning_rate': 0.132,\n",
       "   'depth': 3,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'},\n",
       "  'control': {'iterations': 58,\n",
       "   'learning_rate': 0.496,\n",
       "   'depth': 9,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c8e125-65e0-49b9-b2dd-94e9f0021fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lvl_0': {'meta': {'control_name': 0}},\n",
       " 'lvl_1': {'treatment': {'iterations': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'depth': 6,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'},\n",
       "  'control': {'iterations': 30,\n",
       "   'learning_rate': 0.05,\n",
       "   'depth': 4,\n",
       "   'loss_function': 'Logloss',\n",
       "   'eval_metric': 'AUC'}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"lvl_0\": {\n",
    "    \"meta\": {\n",
    "      \"control_name\": 0\n",
    "    }\n",
    "  },\n",
    "  \"lvl_1\": {\n",
    "    \"treatment\": {\n",
    "      \"iterations\": 20,\n",
    "      \"learning_rate\": 0.1,\n",
    "      \"depth\": 6,\n",
    "      \"loss_function\": \"Logloss\",\n",
    "      \"eval_metric\": \"AUC\"\n",
    "    },\n",
    "    \"control\": {\n",
    "      \"iterations\": 30,\n",
    "      \"learning_rate\": 0.05,\n",
    "      \"depth\": 4,\n",
    "      \"loss_function\": \"Logloss\",\n",
    "      \"eval_metric\": \"AUC\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb78c2-277a-49ce-a0c3-bbb787af8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config_for(catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377a27d-65f9-46c1-a51b-c7363cef9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_random_config():\n",
    "    # Генерируем случайные значения для гиперпараметров\n",
    "    treatment_iterations = random.randint(10, 100)\n",
    "    treatment_learning_rate = round(random.uniform(0.01, 0.5), 3)\n",
    "    treatment_depth = random.randint(1, 10)\n",
    "\n",
    "    control_iterations = random.randint(10, 100)\n",
    "    control_learning_rate = round(random.uniform(0.01, 0.5), 3)\n",
    "    control_depth = random.randint(1, 10)\n",
    "\n",
    "    # Формируем конфигурацию\n",
    "    config = {\n",
    "        \"lvl_0\": {\n",
    "            \"meta\": {\n",
    "                \"control_name\": 0\n",
    "            }\n",
    "        },\n",
    "        \"lvl_1\": {\n",
    "            \"treatment\": {\n",
    "                \"iterations\": treatment_iterations,\n",
    "                \"learning_rate\": treatment_learning_rate,\n",
    "                \"depth\": treatment_depth,\n",
    "                \"loss_function\": \"Logloss\",\n",
    "                \"eval_metric\": \"AUC\"\n",
    "            },\n",
    "            \"control\": {\n",
    "                \"iterations\": control_iterations,\n",
    "                \"learning_rate\": control_learning_rate,\n",
    "                \"depth\": control_depth,\n",
    "                \"loss_function\": \"Logloss\",\n",
    "                \"eval_metric\": \"AUC\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return config\n",
    "\n",
    "# Генерация 5 случайных конфигураций\n",
    "for i in range(5):\n",
    "    random_config = generate_random_config()\n",
    "    print(f\"Random Config {i+1}:\")\n",
    "    print(random_config)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce31f0cb-8ba4-411a-b14c-9a1c26543412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_train_test(ds_name, features_percent):\n",
    "    \"\"\"\n",
    "    Возвращает путь по имени датасета и проценту фичей в нем\n",
    "    \"\"\"\n",
    "\n",
    "    path_to_data_train = f'../data/{ds_name}/{features_percent}/train.tsv'\n",
    "    path_to_data_test = f'../data/{ds_name}/{features_percent}/test.tsv'\n",
    "\n",
    "    return path_to_data_train, path_to_data_test\n",
    "\n",
    "\n",
    "def train_test_model(ds_name, features_percent, factory, config, compressions=None, batch_size=32, max_size=100000):\n",
    "    \"\"\"\n",
    "    Обучает модель, предиктит, сохраняет информацию о модели и добавляет статистики в общую таблицу\n",
    "    \"\"\"\n",
    "    train_path, test_path = get_paths_train_test(ds_name=ds_name, features_percent=features_percent)\n",
    "    model, train, test = factory.create(config, train_path, test_path)\n",
    "    model.fit(train)\n",
    "    predicted = model.predict(test)\n",
    "    write(model, test, predicted, ds_name=ds_name, features_percent=features_percent, compressions=compressions,\n",
    "          batch_size=batch_size, max_size=max_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f14d6c9-27ae-4dbe-83ea-9f1bea8d2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_paths_train_test(\"lazada\", 50)\n",
    "from src.factory import TModelFactory\n",
    "model, train, test = factory.create(config, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9741fc99-8ad1-4060-8eab-5028d2febf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 11:37:45,384] A new study created in memory with name: no-name-44b42cb5-3190-441b-8abe-69406bb8abf2\n",
      "[W 2025-02-22 11:37:45,477] Trial 0 failed with parameters: {'n_estimators': 180, 'max_depth': 3, 'min_samples_split': 10} because of the following error: TypeError('can only concatenate str (not \"numpy.int64\") to str').\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/_utils.py\", line 72, in __call__\n",
      "    return self.func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"causalml/inference/tree/uplift.pyx\", line 2508, in causalml.inference.tree.uplift.UpliftRandomForestClassifier.bootstrap\n",
      "  File \"causalml/inference/tree/uplift.pyx\", line 498, in causalml.inference.tree.uplift.UpliftTreeClassifier.fit\n",
      "  File \"causalml/inference/tree/uplift.pyx\", line 2186, in causalml.inference.tree.uplift.UpliftTreeClassifier.growDecisionTreeFrom\n",
      "TypeError: can only concatenate str (not \"numpy.int64\") to str\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/2h/f3088zln2y36htvcq0wjvt94_1rc11/T/ipykernel_9441/3398558468.py\", line 33, in objective\n",
      "    model.fit(X_train, treatment_train, y_train)\n",
      "  File \"causalml/inference/tree/uplift.pyx\", line 2492, in causalml.inference.tree.uplift.UpliftRandomForestClassifier.fit\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 1754, in _retrieve\n",
      "    self._raise_error_fast()\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n",
      "    error_job.get_result(self.timeout)\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 745, in get_result\n",
      "    return self._return_or_raise()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 763, in _return_or_raise\n",
      "    raise self._result\n",
      "TypeError: can only concatenate str (not \"numpy.int64\") to str\n",
      "[W 2025-02-22 11:37:45,479] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.int64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/ogrobertino/new_diploma/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"causalml/inference/tree/uplift.pyx\", line 2508, in causalml.inference.tree.uplift.UpliftRandomForestClassifier.bootstrap\n  File \"causalml/inference/tree/uplift.pyx\", line 498, in causalml.inference.tree.uplift.UpliftTreeClassifier.fit\n  File \"causalml/inference/tree/uplift.pyx\", line 2186, in causalml.inference.tree.uplift.UpliftTreeClassifier.growDecisionTreeFrom\nTypeError: can only concatenate str (not \"numpy.int64\") to str\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     43\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create and fit the model\u001b[39;00m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m UpliftRandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[1;32m     29\u001b[0m                      max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m     30\u001b[0m                     evaluationFunction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL\u001b[39m\u001b[38;5;124m'\u001b[39m, control_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m                      random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatment_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Predict on the test set and calculate the error\u001b[39;00m\n\u001b[1;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/causalml/inference/tree/uplift.pyx:2492\u001b[0m, in \u001b[0;36mcausalml.inference.tree.uplift.UpliftRandomForestClassifier.fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/new_diploma/lib/python3.11/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.int64\") to str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from causalml.inference.tree import UpliftRandomForestClassifier\n",
    "\n",
    "# Create synthetic data\n",
    "def create_data(n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=20, random_state=42)\n",
    "    treatment = np.random.binomial(1, 0.5, size=n_samples)  # Random treatment assignment\n",
    "    return X, treatment, y\n",
    "\n",
    "# Objective function to optimize hyperparameters\n",
    "def objective(trial):\n",
    "    # Create synthetic dataset\n",
    "    X, treatment, y = create_data()\n",
    "    X_train, X_test, treatment_train, treatment_test, y_train, y_test = train_test_split(\n",
    "        X, treatment, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "\n",
    "    # Create and fit the model\n",
    "    model = UpliftRandomForestClassifier(n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                        evaluationFunction='KL', control_name='0',\n",
    "                         random_state=42)\n",
    "\n",
    "    model.fit(X_train, treatment_train, y_train)\n",
    "\n",
    "    # Predict on the test set and calculate the error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Create a study object and optimize\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best hyperparameters: \", study.best_params)\n",
    "    print(\"Best MSE: \", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
